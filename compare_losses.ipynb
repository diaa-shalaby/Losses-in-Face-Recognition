{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO:\n",
    "\n",
    "- [x] Split the dataset into train and test csv files \n",
    "- [ ] Implement **WandB** logging\n",
    "- [ ] Use the train set to create embeddings using the triplet loss and contrastive loss\n",
    "- [ ] Perform Face Classification\n",
    "- [ ] Compare results\n",
    "- [ ] Add to report: \n",
    "        * Follow this structure: https://www.diva-portal.org/smash/get/diva2:1327708/FULLTEXT01.pdf\n",
    "- [ ] Reorganize project "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tqdm\n",
    "import torch\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from losses.contrastive_loss import ContrastiveLoss, ContrastiveDataset\n",
    "from losses.triplet_loss import TripletLoss, TripletDataset\n",
    "from facenet_pytorch import InceptionResnetV1, training\n",
    "from torch.optim import Adam\n",
    "\n",
    "from losses.contrastive_loss import ContrastiveLoss, ContrastiveDataset\n",
    "from torch.utils.data import DataLoader, SequentialSampler"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up WandB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdodz\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/diaa/My_PRinAI/wandb/run-20230507_000756-940wygtr</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dodz/PRinAI/runs/940wygtr' target=\"_blank\">100_epochs_ContrastiveLoss</a></strong> to <a href='https://wandb.ai/dodz/PRinAI' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dodz/PRinAI' target=\"_blank\">https://wandb.ai/dodz/PRinAI</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dodz/PRinAI/runs/940wygtr' target=\"_blank\">https://wandb.ai/dodz/PRinAI/runs/940wygtr</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/dodz/PRinAI/runs/940wygtr?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f5f571c90f0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "# start a new wandb run to track this script\n",
    "wandb.init(\n",
    "    # set the wandb project where this run will be logged\n",
    "    project=\"PRinAI\",\n",
    "    name=\"100_epochs_ContrastiveLoss\",\n",
    "    \n",
    "    # track hyperparameters and run metadata\n",
    "    config={\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"backbone\": \"InceptionResnetV1\",\n",
    "    \"optimizer\": \"Adam\",\n",
    "    \"batch_size\": 24,\n",
    "    \"dataset\": \"LFW\",\n",
    "    \"epochs\": 10,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define some constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_csv = 'lfw_csvs/lfw_cropped_train.csv'\n",
    "test_csv = 'lfw_csvs/lfw_cropped_test.csv'\n",
    "\n",
    "batch_size = 32\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "random_seed = 42"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Triplet Loss"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the triplets dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, SequentialSampler\n",
    "\n",
    "\n",
    "triplet_dataset = TripletDataset(csv_file='/home/diaa/My_PRinAI/lfw_csvs/lfw_cropped_train.csv')\n",
    "\n",
    "triplet_loader = DataLoader(\n",
    "    triplet_dataset,\n",
    "    num_workers=4,\n",
    "    pin_memory=True,\n",
    "    batch_size=batch_size,\n",
    "    sampler=SequentialSampler(triplet_dataset)\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create triplet Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an inception resnet (in train mode):\n",
    "backbone_cont = InceptionResnetV1(\n",
    "    classify=False,\n",
    "    num_classes=len(triplet_dataset.class_to_idx)\n",
    "    ).to(device)\n",
    "\n",
    "# Train the model for 5 epochs with triplet loss\n",
    "optimizer = torch.optim.AdamW(backbone_cont.parameters(), lr=0.001)\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, [5, 10])\n",
    "\n",
    "# Define the triplet loss function\n",
    "triplet_loss = TripletLoss(margin=14).to(device)\n",
    "\n",
    "loss_fn = triplet_loss\n",
    "metrics = {\n",
    "    'fps': training.BatchTimer(),\n",
    "    'acc': training.accuracy\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_net_triplet_loss(model, loader, optimizer, scheduler, epochs):\n",
    "    model.train()\n",
    "    \n",
    "    for epoch in tqdm.tqdm(range(epochs)):\n",
    "        for batch in loader:\n",
    "            # model.zero_grad()  # what's the difference to optimizer.zero_grad()?\n",
    "            anchor_embedding = model(batch[\"anchor\"].to(device))\n",
    "            positive_embedding = model(batch[\"positive\"].to(device))\n",
    "            negative_embedding = model(batch[\"negative\"].to(device))\n",
    "            loss = triplet_loss(anchor_embedding,\n",
    "                                 positive_embedding,\n",
    "                                 negative_embedding)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        scheduler.step()\n",
    "        wandb.log({\"loss\": loss}, step=epoch)\n",
    "        \n",
    "        # Every 100 epochs save model\n",
    "        try:\n",
    "            if epoch % 100 == 0:\n",
    "                print(f\"Epoch {epoch} loss: {loss} \")\n",
    "                torch.save(model.state_dict(), f\"models/100_epochs_triplet_loss_{epoch}.pth\")\n",
    "                print(f\"Model saved at epoch {epoch}\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error saving model at epoch {epoch}: {e}\")\n",
    "            pass\n",
    "\n",
    "            \n",
    "# Creates once at the beginning of training\n",
    "train_net_triplet_loss(model=backbone_cont,\n",
    "                       loader=triplet_loader,\n",
    "                       optimizer=optimizer,\n",
    "                       scheduler=scheduler,\n",
    "                       epochs=1000)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contrastive Loss"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the contrastive dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "contrastive_dataset = ContrastiveDataset(csv_file='/home/diaa/My_PRinAI/lfw_csvs/lfw_cropped_train.csv')\n",
    "contrastive_loader = DataLoader(contrastive_dataset, \n",
    "                    num_workers=4,\n",
    "                    pin_memory=True,\n",
    "                    batch_size=batch_size, \n",
    "                    shuffle=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create contrastive Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an inception resnet (in train mode):\n",
    "backbone_cont = InceptionResnetV1(\n",
    "    classify=False,\n",
    "    num_classes=len(contrastive_dataset.class_to_idx)\n",
    "    ).to(device)\n",
    "\n",
    "# Using Adam optimizer\n",
    "optimizer = torch.optim.AdamW(backbone_cont.parameters(), lr=0.001)\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, [5, 10])\n",
    "\n",
    "contras_loss = ContrastiveLoss().to(device)\n",
    "\n",
    "metrics = {\n",
    "    'fps': training.BatchTimer(),\n",
    "    'acc': training.accuracy\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 loss: 1.1064393520355225 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/200 [00:46<2:35:00, 46.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved at epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 50/200 [35:48<1:46:44, 42.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50 loss: 0.9053357243537903 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 51/200 [36:31<1:46:25, 42.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved at epoch 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 100/200 [1:13:28<1:21:18, 48.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100 loss: 0.9342449903488159 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 101/200 [1:14:15<1:19:42, 48.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved at epoch 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 106/200 [1:19:14<1:10:16, 44.85s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 34\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[39mpass\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[39m# Creates once at the beginning of training\u001b[39;00m\n\u001b[0;32m---> 34\u001b[0m train_net_contrastive_loss(model\u001b[39m=\u001b[39;49mbackbone_cont,\n\u001b[1;32m     35\u001b[0m                             loader\u001b[39m=\u001b[39;49mcontrastive_loader,\n\u001b[1;32m     36\u001b[0m                             optimizer\u001b[39m=\u001b[39;49moptimizer,\n\u001b[1;32m     37\u001b[0m                             scheduler\u001b[39m=\u001b[39;49mscheduler,\n\u001b[1;32m     38\u001b[0m                             epochs\u001b[39m=\u001b[39;49m\u001b[39m200\u001b[39;49m)\n",
      "Cell \u001b[0;32mIn[7], line 6\u001b[0m, in \u001b[0;36mtrain_net_contrastive_loss\u001b[0;34m(model, loader, optimizer, scheduler, epochs)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m tqdm\u001b[39m.\u001b[39mtqdm(\u001b[39mrange\u001b[39m(epochs)):\n\u001b[1;32m      5\u001b[0m     \u001b[39mfor\u001b[39;00m i, (anchor, target_img, label) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(loader):\n\u001b[0;32m----> 6\u001b[0m         anchor \u001b[39m=\u001b[39m anchor\u001b[39m.\u001b[39;49mto(device)\n\u001b[1;32m      7\u001b[0m         target_img \u001b[39m=\u001b[39m target_img\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m      9\u001b[0m         \u001b[39m# Compute embeddings\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def train_net_contrastive_loss(model, loader, optimizer, scheduler, epochs):\n",
    "    model.train()\n",
    "    \n",
    "    for epoch in tqdm.tqdm(range(epochs)):\n",
    "        for i, (anchor, target_img, label) in enumerate(loader):\n",
    "            anchor = anchor.to(device)\n",
    "            target_img = target_img.to(device)\n",
    "            \n",
    "            # Compute embeddings\n",
    "            embeddings_anchor = model(anchor)\n",
    "            embeddings_target = model(target_img)\n",
    "            label = label.to(device)\n",
    "            loss = contras_loss(embeddings_anchor, embeddings_target, label)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        scheduler.step()\n",
    "        wandb.log({\"loss\": loss}, step=epoch)\n",
    "        \n",
    "        # Every 50 epochs save model\n",
    "        try:\n",
    "            if epoch % 50 == 0:\n",
    "                print(f\"Epoch {epoch} loss: {loss} \")\n",
    "                torch.save(model.state_dict(), f\"models/50_epochs_contrastive_loss_{epoch}.pth\")\n",
    "                print(f\"Model saved at epoch {epoch}\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error saving model at epoch {epoch}: {e}\")\n",
    "            pass\n",
    "\n",
    "            \n",
    "# Creates once at the beginning of training\n",
    "train_net_contrastive_loss(model=backbone_cont,\n",
    "                            loader=contrastive_loader,\n",
    "                            optimizer=optimizer,\n",
    "                            scheduler=scheduler,\n",
    "                            epochs=200)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare Loss"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement a simple Siamese network for face verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class SiameseNetwork(nn.Module):\n",
    "    def __init__(self, embedding_model):\n",
    "        super(SiameseNetwork, self).__init__()\n",
    "        \n",
    "        self.embedding_model = embedding_model\n",
    "\n",
    "    def forward(self, input1, input2):\n",
    "        output1 = self.embedding_model(input1)\n",
    "        output2 = self.embedding_model(input2)\n",
    "        \n",
    "        # Calculate Euclidean distance between the output embeddings\n",
    "        distance = F.pairwise_distance(output1, output2)\n",
    "        \n",
    "        return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "del backbone_cont\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_embeddings(embedding_model_path=None):\n",
    "    # load the trained triplet loss state dict\n",
    "    embedding_model = InceptionResnetV1(\n",
    "        classify=False,\n",
    "        num_classes=len(contrastive_dataset.class_to_idx)\n",
    "        ).to(device)\n",
    "    \n",
    "    loss_name = \"backbone model\"\n",
    "    if embedding_model_path:\n",
    "        embedding_model.load_state_dict(torch.load(embedding_model_path))\n",
    "        loss_name = embedding_model_path.split(\"_\")[2] + \" loss\"\n",
    "        \n",
    "    # embedding_model.load_state_dict(torch.load(\"models/100_epochs_triplet_loss_100.pth\"))\n",
    "\n",
    "    # verification_model = SiameseNetwork(triplet_embedding_model).to(device)\n",
    "    embedding_model.eval()\n",
    "\n",
    "    # Create the siames model\n",
    "    verification_model = SiameseNetwork(embedding_model).to(device)\n",
    "\n",
    "    # Test the verification model\n",
    "    verification_model.eval()\n",
    "\n",
    "    # Create a test dataset and loader\n",
    "    test_dataset = ContrastiveDataset(csv_file='/home/diaa/My_PRinAI/lfw_csvs/lfw_cropped_test.csv')\n",
    "    test_loader = DataLoader(\n",
    "        test_dataset,\n",
    "        num_workers=4,\n",
    "        pin_memory=True,\n",
    "        batch_size=1,\n",
    "        sampler=SequentialSampler(test_dataset)\n",
    "    )\n",
    "\n",
    "    distance = []\n",
    "    results = []\n",
    "    for i, batch in enumerate(test_loader):\n",
    "        # Get the anchor and positive images\n",
    "        anchor = batch[0].to(device)\n",
    "        target = batch[1].to(device)\n",
    "        label = batch[2][0]\n",
    "        \n",
    "        # Is target positive or negative?\n",
    "        match = False if label == 0 else True\n",
    "            \n",
    "        # Pass the face images through the Siamese network for verification\n",
    "        distance = verification_model(anchor, target)\n",
    "\n",
    "        # Define a threshold for face verification\n",
    "        threshold = 0.5\n",
    "\n",
    "        # Compare the distance with the threshold\n",
    "        if distance < threshold:\n",
    "            pred_match = True\n",
    "        else:\n",
    "            pred_match = False\n",
    "                    \n",
    "        if match == pred_match:\n",
    "            results.append(1)\n",
    "        else:\n",
    "            results.append(0)\n",
    "            \n",
    "    accuracy = sum(results) / len(results)\n",
    "    print(f\"Accuracy on test set with {loss_name}: {accuracy}\")\n",
    "    \n",
    "    return distance, results, accuracy\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set with contrastive loss: 0.3683409436834094\n",
      "Accuracy on test set with triplet loss: 0.4094368340943683\n"
     ]
    }
   ],
   "source": [
    "distance_contrastive, results_contrastive, accuracy_contrastive = compare_embeddings(\"models/50_epochs_contrastive_loss_100.pth\")\n",
    "distance_triplet, results_triplet, accuracy_triplet = compare_embeddings(\"models/100_epochs_triplet_loss_100.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean distance for triplet loss: 1.8708646297454834\n",
      "Mean distance for contrastive loss: 1.609084963798523\n"
     ]
    }
   ],
   "source": [
    "# Print the mean distance for each loss function\n",
    "print(f\"Mean distance for triplet loss: {float(distance_triplet.mean())}\")\n",
    "print(f\"Mean distance for contrastive loss: {float(distance_contrastive.mean())}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_df = pd.read_csv(train_csv)\n",
    "\n",
    "def create_npz_file(df):\n",
    "    df_paths = df[\"path\"].values\n",
    "\n",
    "    df_img_arrs = []\n",
    "    for path in df_paths:\n",
    "        img = Image.open(path)\n",
    "        img = img.resize((160, 160))\n",
    "        img_arr = np.array(img).transpose(2, 0, 1) / 255\n",
    "        df_img_arrs.append(img_arr)\n",
    "        \n",
    "    df_img_arrs = np.array(df_img_arrs)\n",
    "    np.savez(\"lfw_cropped_train.npz\", df_img_arrs)\n",
    "        \n",
    "create_npz_file(train_df)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# develop a classifier for the 5 Celebrity Faces Dataset\n",
    "from sklearn.preprocessing import LabelEncoder, accuracy_score, Normalizer\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "# load dataset\n",
    "data = load('5-celebrity-faces-embeddings.npz')\n",
    "trainX, trainy, testX, testy = data['arr_0'], data['arr_1'], data['arr_2'], data['arr_3']\n",
    "print('Dataset: train=%d, test=%d' % (trainX.shape[0], testX.shape[0]))\n",
    "# normalize input vectors\n",
    "in_encoder = Normalizer(norm='l2')\n",
    "trainX = in_encoder.transform(trainX)\n",
    "testX = in_encoder.transform(testX)\n",
    "# label encode targets\n",
    "out_encoder = LabelEncoder()\n",
    "out_encoder.fit(trainy)\n",
    "trainy = out_encoder.transform(trainy)\n",
    "testy = out_encoder.transform(testy)\n",
    "# fit model\n",
    "model = SVC(kernel='linear', probability=True)\n",
    "model.fit(trainX, trainy)\n",
    "# predict\n",
    "yhat_train = model.predict(trainX)\n",
    "yhat_test = model.predict(testX)\n",
    "# score\n",
    "score_train = accuracy_score(trainy, yhat_train)\n",
    "score_test = accuracy_score(testy, yhat_test)\n",
    "# summarize\n",
    "print('Accuracy: train=%.3f, test=%.3f' % (score_train*100, score_test*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
